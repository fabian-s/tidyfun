---
title: "Introducing tidyfun"
author: "Fabian Scheipl"
date: "`r Sys.Date()`"
output: 
    rmarkdown::html_vignette:
      fig_width: 12
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Introducing tidyfun}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "##",
  fig.width = 8, fig.height = 5.5)

library(tidyverse)
library(refund)
library(ggplot2)
library(viridisLite)
theme_set(theme_minimal())
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

library("tidyfun")
#try(devtools::load_all("~/fda/tidyfun"))


pal_5 = viridis(7)[-(1:2)]
set.seed(1221)
```

## **`tidyfun`**

The goal of **`tidyfun`** is to provide accessible and well-documented software 
that **makes functional data analysis in `R` easy**, specifically:  
data wrangling and exploratory analysis.

**`tidyfun`** provides:  

- new **data types** for representing functional data: **`tfd`** & **`tfb`**

- arithmetic **operators**, descriptive **statistics** and **graphics** functions for such data

- `tidyverse`-verbs for handling functional data **inside** data frames.

# `tf`-Class: Definition

##  `tf`-class

**`tf`** is a new data type for (vectors of) functional data: 

- an abstract superclass for functional data in 2 forms:
    - as (argument, value)-tuples: subclass **`tfd`**, also irregular or sparse
    - or in basis representation: subclass **`tfb`**
    
- basically, a `list` of numeric vectors  
  (... since `list`s work well as columns of data frames ...)

- with additional attributes that define *function-like* behavior:
    - how to **evaluate** the given "functions" for new arguments
    - their **domain** 
    - the **resolution** of the argument values

- `S3` based

## Example Data

Some example data used in this vignette (the code used to create these will be explained later) --

a prepped version of the `refund::DTI` dataset with 2 functional covariates:
```{r load-dti}
dti <- with(refund::DTI, 
            data.frame(
              id = ID, 
              sex = sex, 
              case = factor(ifelse(case, "MS", "control")))
            ) %>%
  as.tbl %>%
  mutate(cca = tfd(refund::DTI$cca, seq(0,1, l = 93)) %>%
           tfd(arg = seq(0,1,l = 93)),
         rcst = tfd(refund::DTI$rcst, seq(0, 1, l = 55)))
dti
```

and a simple 5 element vector of functions on a regular grid:
```{r ex-def}
ex_data <- dti$cca[1:5, seq(0, 1, l = 93), interpolate = TRUE]
rownames(ex_data) <- LETTERS[1:5]
ex <- tfd(ex_data, signif = 2)
ex
```
```{r, ex-fig}
plot(ex, xlim = c(-0.15, 1), col = pal_5)
text(x = -.1, y = ex[,0.07], labels = names(ex), col = pal_5)
```

## **`tf`** subclass: **`tfd`**

**`tfd`** objects contain "raw" functional data: 

 - represented as a list of **`evaluations`** $f_i(t)|_{t=t'}$ and corresponding **`arg`**ument vector(s) $t'$
 - have a **`domain`**:  the range of valid **`arg`**s.

```{r}
ex %>% tf_evaluations() %>% str
ex %>% tf_arg() %>% str
ex %>% tf_domain() 
```

- each **`tfd`**-vector contains an **`evaluator`** function that defines how to inter-/extrapolate `evaluations` between `arg`s (and remembers results of previous calls)

```{r}
tf_evaluator(ex) %>% str
tf_evaluator(ex) <- tf_approx_spline
```

- **`tfd`** has subclasses for regular data with a common grid and irregular or sparse data,
like the `rcst` measurements in our `dti` data.

```{r}
dti$rcst[1:2]
dti$rcst[1:2] %>% tf_arg() %>% str
dti$rcst[1:2] %>% plot(pch = "x", col = viridis(2))
```

## **`tf`** subclass: **`tfb`**

Functional data in basis representation: 

 - represented as a list of **`coefficients`** and a common **`basis_matrix`** of basis function evaluations on a vector of `arg`-values.
 - contains a **`basis`** function that defines how to compute the basis for new **`arg`**s and how to differentiate or integrate it.
- (internal) flavors: 
    - `tfb_spline`: uses `mgcv`-spline bases 
    - `tfb_fpc`: uses functional principal components 
- significant memory and time savings:
```{r}
refund::DTI$cca %>% object.size() %>% print(units = "Kb")
dti$cca %>% object.size() %>% print(units = "Kb")
dti$cca %>% tfb(verbose = FALSE) %>% object.size() %>% print(units = "Kb")
```

### **`tfb_spline`**: spline basis

- default for `tfb()`
- accepts all arguments of `mgcv`'s `s()`-syntax: control basis type `bs`, basis dimension `k`, penalty order `m`
- also does non-Gaussian fits: `family` argument 
    - all exponential families
    - but also: $t$-distribution, ZI-Poisson, Beta, ... 

```{r, message = TRUE}
ex_b <- ex %>% tfb()
ex_b[1:2]
ex[1:2] %>% tfb(bs = "tp", k = 55)
ex[1:2] %>% tfb(bs = "ps", m = c(2,1), family = mgcv::betar(link = "cloglog"))
```

### Penalization: 

**Function-specific (default), none**, prespecified (`sp`), or global: 

```{r}
layout(t(1:2))
ex  %>% plot()
ex_b %>% plot(col = "red")
ex %>% tfb(k = 35, penalized = FALSE) %>% lines(col = "blue")
ex %>% tfb(sp = .001) %>% lines(col = "orange")
```

**"Global" smoothing**:  

1. estimate smoothing parameters for subsample (~10\%) of curves
2. apply geometric mean of estimated smoothing parameters to smooth *all* curves

**Advantages:**

- (much) faster than optimizing penalization for each curve
- should scale well for larg-ish datasets

**Disadvantages**

- no real borrowing of information across curves (very sparse or functional fragment data, e.g.)
- still requires more observations than basis functions *per curve*
- subsample could miss small subgroups with different roughness, over-/undersmooth parts of the data, see below.

```{r, echo = FALSE}
set.seed(1212)
raw <- c(
  tf_rgp(5, scale = 0.2, nugget = .05, arg = 101L) - 5,
  tf_rgp(5, scale = 0.02, nugget = .05, arg = 101L),
  tf_rgp(5, scale = 0.002, nugget = .05, arg = 101L) + 5)
```

Dataset with heterogeneous roughness:
```{r}
layout(t(1:3))
clrs <- scales::alpha(sample(viridis(15)), .5)
plot(raw, main = "raw", col = clrs)
plot(tfb(raw, k = 55), main = "separate", col = clrs)
plot(tfb(raw, k = 55, global = TRUE), main = "global", col = clrs)
```

###  **`tfb`** FPC-based

- uses first few eigenfunctions computed from a simple unregularized (weighted) SVD of the data matrix by default
- corresponding FPC basis and mean function saved as `tfd`-object
- observed functions are linear combinations of those.
- amount of "smoothing" can be controlled (roughly!) by setting the 
minimal *percentage of variance explained* `pve` 

```{r}
(ex_fpc <- ex %>% tfb_fpc(pve = .999))
```

```{r}
layout(t(1:2))
ex %>% plot()
ex_fpc  %>% plot(col = "red", ylab = "tfb_fpc(ex)")
ex  %>% tfb_fpc(pve = .1) %>% lines(col = "blue", lty = 2)
```

`tfb_fpc` is currently only implemented for data on identical 
(but possibly non-equidistant) grids. The **`{refunder}`** `rfr_fpca`-functions 
provide FPCA methods for irregular and sparse data and regularized/smoothed FPCA.

# `tf`-Class: Methods

**`tidyfun`** implements almost all types of operations that are available for conventional
numerical or logical vectors for `tf`-vectors as well, so you can:

### subset & subassign:

```{r}
ex[1:2]
ex[1:2] = ex[2:1]
ex
```

### compare & compute:

```{r, echo = FALSE}
n_ex = names(ex)
ex = unname(ex)
```

```{r}
ex[1] + ex[1] == 2 * ex[1]
log(exp(ex[2])) == ex[2]
ex - (2:-2) != ex 
```

```{r, echo = FALSE}
names(ex) = n_ex
```

### summarize: 

```{r}
c(mean = mean(ex), sd = sd(ex))

tf_depth(ex) ## Modified Band-2 Depth (Ã  la Sun/Genton/Nychka, 2012), others to come.
median(ex) == ex[which.max(tf_depth(ex))]
```

In addition, **`tidyfun`** provides methods specific for functional data:

### evaluate:

`tf`-objects have a special `[`-operator: Its second argument specifies 
`arg`ument values at which to evaluate the functions and has some additional options, 
so it's easy to get point values for `tf` objects: 

```{r, warning  = FALSE}
ex[1:2, seq(0, 1, l = 3)]
ex["B", seq(0, .15, l = 3), interpolate = FALSE]
ex[1:2, seq(0, 1, l = 7), matrix = FALSE] %>% str
```


### (simple, local) smoothing

```{r}
layout(t(1:3))
ex %>% plot(alpha = .2, ylab = "lowess")
ex %>% tf_smooth("lowess") %>% lines(col = pal_5)

ex %>% plot(alpha = .2, ylab = "rolling median (k=5)")
ex %>% tf_smooth("rollmedian", k = 5) %>% lines(col = pal_5)

ex %>% plot(alpha = .2, ylab = "Savitzky-Golay (quartic, 11 steps)")
ex %>% tf_smooth("savgol", fl = 11) %>% lines(col = pal_5)
```

### differentiate & integrate:

```{r}
layout(t(1:3))
ex %>% plot(col = pal_5)
ex %>% tf_smooth() %>% tf_derive() %>% plot(col = pal_5, ylab = "tf_derive(tf_smooth(ex))")
ex %>% tf_integrate(definite = FALSE) %>%  plot(col = pal_5)
```
```{r}
ex %>% tf_integrate()
```

### query

**`tidyfun`** makes it easy to find (ranges of) `arg`uments $t$ satisfying a condition on `value` $f(t)$ (and `arg`ument $t$):

```{r}
ex %>% tf_anywhere(value > .65)
ex[1:2] %>% tf_where(value > .6, "all")
ex[2] %>% tf_where(value > .6, "range")
ex %>% tf_where(value > .6 & arg > .5, "first")
```

### zoom & query

```{r, ex-fig2}
ex %>% plot(xlim = c(-0.15, 1), col = pal_5, lwd = 2)
text(x = -.1, y = ex[,0.07], labels = names(ex), col = pal_5, cex = 1.5)
median(ex) %>% lines(col = pal_5[3], lwd = 4)
```

```{r}
ex %>% tf_where(value == max(value), "first")
ex[c("A", "D")] %>% tf_zoom(.5, 1) %>% tf_where(value == max(value), "first")
ex %>% tf_zoom(0.2, 0.6) %>% tf_anywhere(value <= median(ex)[, arg])
```

### convert & construct

To & from list, matrix or data frame with `"id"`,`"arg"`,`"value"`-columns:

```{r}
ex_matrix <- ex %>% as.matrix()
ex_matrix[1:2, 1:3]

ex_df <- ex %>% as.data.frame()
str(ex_df)

ex_matrix[1:2, ] %>% tfd()

tfd(ex_df) == tfd(ex_matrix)
```

# New geoms and stats for functional data for customizable `ggplot2` graphics

### visualize with `base` graphics

```{r ex-fig3}
layout(t(1:2))

plot(ex, type = "spaghetti")
lines(c(median(ex), mean(ex)), col = c(2, 4))

plot(ex, type = "lasagna", col = viridis(50))
```

### visualize with `ggplot2`

**Pasta-themed** `geom`s and plots with for functional data:

- **`geom_spaghetti`** for lines
- **`geom_meatballs`**  for (lines &) points
- **`gglasagna`** with **`order`**-arguments to sort the lasagna layers
- **`geom_capellini`** for little sparklines / glyphs on maps etc.

```{r, dti-fig1}
ggplot(dti) + 
  geom_spaghetti(aes(y = cca, col = case, alpha = .2 + .4*(case == "control"))) +
  facet_wrap(~ sex) + scale_alpha(guide = 'none', range = c(.2, .4))
```

```{r, dti-fig2}  
gglasagna(dti, cca, 
  order = tf_integrate(cca, definite = TRUE), arg = seq(0,1, l = 101)) + 
  theme(axis.text.y = element_text(size = 6)) + 
    facet_wrap(~ case, ncol = 2, scales = "free")
```

Some data prep for the iconic Canadian Weather data:
```{r}
canada <- data.frame(
  place = fda::CanadianWeather$place, 
  region = fda::CanadianWeather$region, 
  lat = fda::CanadianWeather$coordinates[,1], 
  lon = -fda::CanadianWeather$coordinates[,2], 
  region = fda::CanadianWeather$region)

canada$temp <- tfd(t(fda::CanadianWeather$dailyAv[,,1]), arg = 1:365)
canada$precipl10 <- tfd(t(fda::CanadianWeather$dailyAv[,,3]), arg = 1:365) %>%
  tf_smooth

canada_map <- 
  data.frame(maps::map("world", "Canada", plot = FALSE)[c("x", "y")]) 
```

Now plot a map of Canada with annual temperature averages in red, 
precipitation in blue: 
```{r}
 ggplot(canada, aes(x = lon, y = lat)) + 
   geom_capellini(aes(tf = precipl10), width = 4, height = 5, colour = "blue", 
     line.linetype = 1) +
   geom_capellini(aes(tf = temp), width = 4, height = 5, colour = "red",
     line.linetype = 1) +
   geom_path(data = canada_map, aes(x = x, y = y), alpha = .1) +
   coord_quickmap()
```


# Wrangling `tf`-objects inside data frames

For a more detailed discussion of the topic of this section, please see the [`Data Manipulation`](https://fabian-s.github.io/tidyfun/articles/02_Data_Manipulation.html) vignette.


### wrangling `tf`-objects inside data frames: `dplyr`

**`dplyr`** verbs **`filter`**, **`select`**, **`mutate`**, **`summarize`** work on **`tf`**-columns - e.g.:

```{r, dplyr}
# group-wise functional means:
dti %>% group_by(case, sex) %>% 
  summarize(mean_rcst = mean(rcst, na.rm = TRUE)) %>% 
  ungroup()
# which subjects go below cca = .26:
dti %>% filter(tf_anywhere(cca, value < .26))
# mutate and create derived functional data
dti %>%
  mutate(
    rcst_smooth = tfb(rcst, k = 15, verbose = FALSE),
    rcst_deriv = tf_derive(rcst_smooth)
  ) %>%
  glimpse
```

### wrangling `tf`-objects inside data frames: `tidyr`

**`tidyfun`** provides `tf_` variants of `tidyr`-verbs to reshape and reformat functional data while keeping it in sync with other covariates:


- `tf_spread:` `tf` $\rightarrow$ columns for each `arg`
- `tf_gather:` columns for each `arg` $\rightarrow$ `tf`

```{r, tidyr}
# spread tf out into columns for each arg
dti_wide = dti %>% tf_spread(cca); dti_wide[, 1:7] %>% glimpse()  

# collect all columns into a single tf-column 
# (... will try to guess arg from column names, name of tf from their prefix)
dti_wide %>% tf_gather(matches("cca_")) %>% glimpse()
```

- `tf_unnest:` `tf` $\rightarrow$ data in long format (`id`, `arg`, `value`)  
- `tf_nest  :` data in long format (`id`, `arg`, `value`)  $\rightarrow$ `tf`

```{r, tidyr2}
# unnest tf by writing 3 loong columns id, arg, value:
# (will try to avoid unnecessary duplication of columns)
dti_long = dti %>% tf_unnest(cca); dti_long %>% glimpse()  
# nest tf by writing 3 loong columns id, arg, value:
dti_long %>% tf_nest(cca_value, .id = cca_id, .arg = cca_arg) %>% glimpse()
```

Note that `left/right_join`-operations as well as `bind_rows` do not currently work reliably 
for tables with `tfd` or `tfb`-columns, see [tidyfun/issues/53](https://github.com/fabian-s/tidyfun/issues/53). `bind_rows` can be easily avoided by using `rbind`, which still works, instead.
