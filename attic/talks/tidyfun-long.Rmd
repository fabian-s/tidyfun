---
title: '**`tidyfun`**: Tidy Functional Data'
subtitle: 'A new framework for working with functional data in **`R`**'
date: ""
author: 
    - "Fabian Scheipl$^1$"
    - "Jeff Goldsmith$^2$"
institute: 
    - "$^1$: Dept. of Statistics, LMU Munich"
    - "$^2$: Columbia University Mailman School of Public Health"
output: 
  beamer_presentation: 
    keep_tex: yes 
    includes:
      in_header: header.tex
    highlight: pygments
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(
  collapse = TRUE,
  size = 'footnotesize',
  cache = TRUE,
  fig.width = 8, fig.height = 5.5, 
  warning = FALSE, message = FALSE)

library(tidyverse)
library(refund)
library(ggplot2)
library(patchwork)
library(viridisLite)
theme_set(theme_minimal())
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

devtools::load_all()

pal_5 = viridis(7)[-(1:2)]
```

```{r load, echo=FALSE, include=FALSE}
dti = with(refund::DTI, 
  data.frame(id = ID, sex = sex, 
    case = factor(ifelse(case, "MS", "control")))) %>% as.tbl %>% 
        mutate(cca = tfd(DTI$cca, seq(0,1, l = 93), resolution = .01) %>%
                     tfd(arg = round(seq(0,1,l = 93), 3)),
               rcst = tfd(DTI$rcst, round(seq(0, 1, l = 55), 3), resolution = .01))
set.seed(1221)
ex_data = dti$cca[1:5, seq(0, 1, l = 93), interpolate = TRUE]
rownames(ex_data) = LETTERS[1:5]
ex = tfd(ex_data, signif = 2)
dti_wide <- select(dti, -rcst) %>% tf_spread
dti_long <- select(dti, -rcst) %>% tf_unnest
dti_mat <- select(dti, -rcst)
dti_mat$cca <- as.matrix(dti$cca) 
attr(dti_mat$cca, "arg") <- NULL
dti_mat$cca <- unname(dti_mat$cca)
```

## Functional Data

**Painful** to work with:

- huge amounts of data
- regular grids? irregular grids?
- work with:
    - raw data?
    - smooth/interpolated?
    - basis representations?

## Functional Data

**Painful:**  
Two (2.5, actually..) bad options to keep it in the same data.frame as the rest of
your data:

 1. **wide** format:  
- way too many weird columns
- need to keep track of argument values $t$ separately somehow:

```{r, echo = FALSE}
glimpse(dti_wide)
```

## Functional Data

**Painful:**  
Two (2.5, actually..) bad options to keep it in the same data.frame as the rest of
your data:
 

 2. **long** format:  

- unwieldy amounts of rows, lots of duplication for non-functional data
- need to keep track of grouping structure (which rows belong to the
same curve?) throughout
- infeasible if we have more than one function per observational unit

```{r, echo = FALSE}
glimpse(dti_long)
```

## Functional Data

**Painful** to work with:

Third bad option: **matrix columns** in a `data.frame`.

Sucks, too:

- not really well supported (breaks entire `tidyverse`, much unexpected behavior in `base`)
- more trouble than it’s worth: doesn’t solve how to keep track of
argument values

```{r}
str(dti_mat)
select(dti_mat, cca) %>% glimpse
```

## Functional Data

Despite all that, people keep measuring ever more of the damn things.

Let's make dealing with functional data in **`R`** less painful.

# Start at the end...

## This is what we're aiming for:

```{r, out.height = '.4\\textheight', fig.width = 6, fig.height = 2}
# group-wise functional medians:
medians <- dti %>% group_by(case, sex) %>% summarize(median_rcst = median(rcst))
ggplot(medians) + geom_spaghetti(aes(y = median_rcst, col = sex, linetype = case))
```

## This is what we're aiming for:

```{r, size = 'tiny', R.options= list(width = 120)}
dti[, -1]
```

## **`tidyfun`**

The goal of **`tidyfun`** is to provide accessible and well-documented software 
that **makes functional data analysis in `R` easy**, specifically:  
data wrangling and exploratory analysis.

**`tidyfun`** provides:  

- new **data types** for representing functional data: **`tfd`** & **`tfb`**

- arithmetic **operators**, descriptive **statistics** and **graphics** functions for such data

- `tidyverse`-verbs for handling functional data **inside** data frames.

## Plan for today

- Overview over `tidyfun`'s data types and methods
- Discussion & Feedback: 
    - What's stupid? 
    - What is too complicated? 
    - What am I missing?  

# `tf`-Class: Definition

##  `tf`-class

**`tf`** is a new data type for (vectors of) functional data: 

- an abstract superclass for functional data in 2 forms:
    - as (argument, value)-tuples: subclass **`tfd`**, also irregular or sparse
    - or in basis representation: subclass **`tfb`**
    
- basically, a glorified `list` of numeric vectors  
  (... since `list`s work well as columns of data frames ...)

- with additional attributes that define *function-like* behavior:
    - how to **evaluate** the given "functions" for new arguments
    - their **domain** 
    - the **resolution** of the argument values

- `S3` based

## Example Data

```{r, ex-fig, echo = FALSE, out.height = '.45\\textheight', fig.width = 6, fig.height = 4}
plot(ex,  xlim = c(-0.15, 1), col = pal_5)
text(x = -.1, y = ex[,0.07], labels = names(ex), col = pal_5)
```

```{r}
ex
```

## Example Data

```{r}
glimpse(dti)
```

## **`tf`** subclass: **`tfd`**

**`tfd`** objects contain "raw" functional data:

 - represented as a list of **`evaluations`** $f_i(t)|_{t=\boldmath{t'}}$ and corresponding **`arg`**ument vector(s) $\boldmath{t'}$
 - has a **`domain`**:  the range of valid **`arg`**s.

```{r}
ex %>% tf_evaluations() %>% str

ex %>% tf_arg() %>% str

ex %>% tf_domain()
```

## **`tf`** subclass: **`tfd`**

- contains an **`evaluator`** function that defines how to inter-/extrapolate `evaluations` between `arg`s (and remembers results of previous calls)

```{r}
tf_evaluator(ex) %>% str
tf_evaluator(ex) <- tf_approx_spline
```

## **`tf`** subclass: **`tfd`**

- **`tfd`** has subclasses for regular data with a common grid and irregular or sparse data.

```{r, out.height = '.30\\textheight', fig.width = 6, fig.height = 4.5}
dti$rcst[1:2]

dti$rcst[1:2] %>% tf_arg() %>% str

dti$rcst[1:2] %>% plot(pch = "x", col = viridis(2))
```

## **`tf`** subclass: **`tfd`**

```{r}
dti$cca[1:3] %>% str(1)
```

## **`tf`** subclass: **`tfb`**

Functional data in basis representation:

 - represented as a list of **`coefficients`** and a common **`basis_matrix`** of basis function evaluations on a vector of `arg`-values.
 - contains a **`basis`** function that defines how to compute the basis for new **`arg`**s and how to differentiate/integrate.
- (internal) flavors: 
    - `tfb_spline`: **`mgcv`**-spline bases 
    - `tfb_fpc`: FPCs (wavelets to be added)

- significant memory (and time) savings:
```{r, cache = TRUE}
refund::DTI$cca %>% object.size() %>% print(units = "Kb")

dti$cca %>% object.size() %>% print(units = "Kb")

dti$cca %>% tfb(verbose = FALSE) %>% object.size() %>% print(units = "Kb")
```

## **`tf`** subclass: **`tfb`**

```{r}
dti$cca[1:3] %>% tfb(verbose = FALSE) %>% str(1)
```

## **`tf`** subclass: **`tfb_spline`**
- default for `tfb()`
- accepts all arguments of `mgcv`'s `s()`-syntax: control basis type `bs`, basis dimension `k`, penalty order `m`
- also does non-Gaussian fits: `family` argument 
    - all exponential families
    - but also: $t$-distribution (robust smoothing?), ZI-Poisson (accelerometry?), Beta (), ... 

## **`tf`** subclass: **`tfb_spline`**

```{r, message = TRUE}
ex_b = ex %>% tfb(); ex_b[1:2]
ex[1:2] %>% tfb(bs = "tp", k = 55)
ex[1:2] %>% tfb(bs = "ps", m = c(2,1), family = betar(link = "cloglog"))
```

## **`tf`** subclass: **`tfb`** spline basis

- penalization: function-specific by default, none, prespecified (`sp`), or global 

```{r, eval = FALSE}
ex  %>% plot()
ex %>% tfb() %>% plot(col = "red")
ex %>% tfb(k = 35, penalized = FALSE) %>% lines(col = "blue")
```
```{r, echo = FALSE, results = 'hide', out.height = '.4\\textheight', fig.width = 8, fig.height = 4}
layout(t(1:2))
plot(ex, alpha = 1)
plot(ex %>% tfb(verbose = FALSE), col = "red")
lines(tfb(ex, k = 35, penalized = FALSE, verbose = FALSE), col = "blue")
```

## **`tf`** subclass: **`tfb`** spline basis

- penalization: function-specific by default, prespecified, none, or global 

```{r, eval = FALSE}
ex  %>% plot()
ex %>% tfb() %>% plot(col = "red")
ex %>% tfb(sp = .001) %>% lines(col = "cyan")
```
```{r, echo = FALSE, results = 'hide', out.height = '.4\\textheight', fig.width = 8, fig.height = 4}
layout(t(1:2))
plot(ex, alpha = 1)
plot(ex %>% tfb(verbose = FALSE), col = "red")
lines(tfb(ex, sp = .001, col = "cyan"))
```

## **`tf`** subclass: **`tfb`** spline basis

**Global** smoothing:  

1. estimate smoothing parameters for subsample (~10\%) of curves
2. apply geometric mean of estimated smoothing parameters to smooth *all* curves

**Good:**

- (much) faster than optimizing penalization for each curve
- should scale well for larg-ish datasets

**Not good:**

- no real borrowing of information across curves (very sparse or functional fragment data, e.g.)
- needs more observations than basis functions *per curve*.
- subsample could miss small subgroups with different roughness

*Should global smoothing be the default?*

## **`tf`** subclass: **`tfb`** spline basis

**Global** smoothing: 

```{r, echo = FALSE}
set.seed(1212)
raw <- c(
  tf_rgp(5, scale = 0.2, nugget = .05, arg = 101L) - 5,
  tf_rgp(5, scale = 0.02, nugget = .05, arg = 101L),
  tf_rgp(5, scale = 0.002, nugget = .05, arg = 101L) + 5)
```

```{r, eval = FALSE}
raw %>% plot() 
tfb(raw, k = 55) %>% plot
tfb(raw, k = 55, global = TRUE) %>% plot
```

```{r, echo = FALSE, results = 'hide', out.height = '.5\\textheight', fig.width = 10, fig.height = 4}
layout(t(1:3))
clrs <- scales::alpha(sample(viridis(15)), .5)
plot(raw, main = "raw", col = clrs)
plot(tfb(raw, k = 55), main = "separate", col = clrs)
plot(tfb(raw, k = 55, global = TRUE), main = "global", col = clrs)
```

## **`tf`** subclass: **`tfb`** FPC-based

- uses either
    - simple unregularized SVD of the data matrix ("`smooth = FALSE`")
    - or smoothed covariance estimate from `refund::fpca.sc`
- corresponding FPC basis and mean function saved as `tfd`-object \& observed functions are simply linear combinations of those.

```{r}
(ex %>% tfb_fpc(smooth = FALSE, pve = .999))
(ex %>% tfb_fpc(pve = .9))
```

## **`tf`** subclass: **`tfb`** FPC-based

```{r, eval = FALSE}
ex %>% plot()
ex %>% tfb_fpc(smooth = FALSE, pve = .999) %>% plot(col = "red")
ex %>% tfb_fpc(pve = .9) %>% lines(col = "blue")
```

```{r, echo = FALSE, results = 'hide', out.height = '.4\\textheight', fig.width = 8, fig.height = 4}
layout(t(1:2))
plot(ex, alpha = 1)
plot(ex  %>% tfb_fpc(smooth = FALSE, pve = .999), col = "red", ylab = "tfb_fpc(ex)")
lines(ex %>% tfb_fpc(pve = .9), col = "blue")
```

# `tf`-Class: Methods

## Subset & subassign

Special `[`-methods:

```{r}
ex[1:2]

ex[1:2] = ex[2:1]
ex
```

## Evaluate

Re-defined second argument for `[`:

```{r, warning  = FALSE}
ex[1:2, seq(0, 1, l = 5)]

ex["B", seq(0, .15, l = 3), interpolate = FALSE]

ex[1:2, c(0, 1), matrix = FALSE] %>% str
```

## Compare & compute

```{r, echo = FALSE}
n_ex = names(ex)

ex = unname(ex)
```

```{r}
ex[1] + ex[1] == 2 * ex[1]

log(exp(ex[2])) == ex[2]

ex - (2:-2) != ex 
```

```{r, echo = FALSE}
names(ex) = n_ex
```

## Summarize 

```{r}
c(mean = mean(ex), sd = sd(ex))

tf_depth(ex) # Modified Band-2 Depth (Sun/Genton/Nychka, 2012), others to come -- which?

median(ex) == ex[which.max(tf_depth(ex))]
```

## (Simple, local) smoothing
```{r, eval  = FALSE}
ex %>% tf_smooth("lowess") %>% plot
ex %>% tf_smooth("rollmedian", k = 5) %>% plot
```
```{r, echo = FALSE, fig.height = 4.5}
layout(t(1:2))
ex %>% plot(alpha = .2, ylab = "lowess")
ex %>% tf_smooth("lowess") %>% lines(col = pal_5)
plot(ex, alpha = .2, ylab = "rolling median (k=5)")
lines(tf_smooth(ex, "rollmedian", k = 5), col = pal_5)
#plot(ex, alpha = .2, ylab = "Savitzky-Golay (quartic, 11 steps)")
#lines(tf_smooth(ex, "savgol", fl = 11), col = pal_5)
```

## Differentiate & integrate
```{r, eval  = FALSE}
ex %>% plot
ex %>% tf_smooth() %>% tf_derive() %>% plot
ex %>% tf_integrate(definite = FALSE) %>% plot
```
```{r, echo = FALSE, fig.height = 4.5}
layout(t(1:3))
plot(ex, col = pal_5)
plot(tf_derive(tf_smooth(tfd(ex, signif = 4))), col = pal_5, ylab = "tf_smooth(ex) %>% tf_derive")
plot(tf_integrate(ex, definite = FALSE), col = pal_5)
```
\vskip -1em
```{r}
ex %>% tf_integrate()
```

## Query

Find `arg`uments $t$ satisfying a condition on `value` $f(t)$ (and `arg`ument $t$):

```{r}
ex %>% tf_anywhere(value > .65)

ex[1:2] %>% tf_where(value > .6, "all")

ex[2] %>% tf_where(value > .6, "range")

ex %>% tf_where(value > .6 & arg > .5, "first")
```

## Zoom & query

```{r, ex-fig2, echo = FALSE, out.height = '.35\\textheight', fig.width = 6.5, fig.height = 4}
plot(ex,  xlim = c(-0.15, 1), col = pal_5, lwd = 2)
text(x = -.1, y = ex[,0.07], labels = names(ex), col = pal_5, cex = 1.5)
lines(median(ex), col = pal_5[3], lwd = 4)
```

```{r}
ex %>% tf_where(value == max(value), "first")

# locations of maxima on [.5, 1]:
ex[c("A", "D")] %>% tf_zoom(.5, 1) %>% tf_where(value == max(value), "first")

# which functions dip below the median curve anywhere in [0.2, 0.6]:
ex %>% tf_zoom(0.2, 0.6) %>% tf_anywhere(value < median(ex)[, arg])
```

## Convert & construct

To & from list, matrix or data frame with `"id"`,`"arg"`,`"value"`-columns:

```{r}
ex_matrix = ex %>% as.matrix(); ex_matrix[1:2, 1:3]

ex_df = ex %>% as.data.frame(); str(ex_df)

ex_matrix[1:2, ] %>% tfd()

tfd(ex_df) == tfd(ex_matrix)
```

## Visualize: `base` 

```{r ex-fig3,  out.height = '.35\\textheight', fig.width = 8, fig.height = 4}
layout(t(1:2))
plot(ex, type = "spaghetti"); lines(c(median(ex), mean(ex)), col = c(2, 4))
plot(ex, type = "lasagna", col = viridis(50))
```

## Visualize: `ggplot2`

**Pasta-themed** `geom`s for functional data:

- **`geom_spaghetti`** for lines
- **`geom_meatballs`**  for (lines &) points
- **`geom_capellini`** for little sparklines / glyphs on maps etc. 
- **`gglasagna`** with **`order`**-aesthetic to sort the lasagna layers

## Visualize: `ggplot2`

```{r, eval = FALSE}
ggplot(dti, aes(y = cca, colour = case)) +
  geom_spaghetti() + facet_wrap(~ sex)
```

```{r, dti-fig1, echo = FALSE, out.height = '.7\\textheight', fig.width = 12, fig.height = 7}
ggplot(dti) + 
  geom_spaghetti(aes(y = cca, col = case, alpha = .2 + .4*(case == "control"))) + facet_wrap(~ sex) + scale_alpha(guide = 'none', range = c(.2, .4))
```

## Visualize: `ggplot2`

```{r, eval = FALSE}
gglasagna(dti, 
          y = cca, 
          order = tf_integrate(cca, definite = TRUE)) +
  facet_wrap(~ case)
```
```{r, dti-fig2, echo = FALSE, out.height = '.7\\textheight', fig.width = 12, fig.height = 7}  
gglasagna(dti[1:100,], y = cca, order = tf_integrate(cca, definite = TRUE)) + 
  theme(axis.text.y = element_text(size = 6)) + 
  facet_wrap(~ case, ncol = 2, scales = "free")
```

## Visualize: `ggplot2`
Plots for spatial functional data:

```{r}
weather <- fda::CanadianWeather
canada <- data.frame(
   place = weather$place,
   region = weather$region,
   lat = weather$coordinates[,1],
   lon = -weather$coordinates[,2],
   region = weather$region)
canada$temp <- tfd(t(weather$dailyAv[,,1]), arg = 1:365)
canada$precipl10 <- tfd(t(weather$dailyAv[,,3]), arg = 1:365) %>% tf_smooth
glimpse(canada)
```

## Visualize: `ggplot2`

```{r, out.height = '.5\\textheight', fig.width = 10, fig.height = 5}
canada_map <-
   data.frame(maps::map("world", "Canada", plot = FALSE)[c("x", "y")])
 # maps of Canada with annual temperature averages in red, precipitation in blue:
map_plot <- ggplot(canada, aes(x = lon, y = lat)) + 
  geom_path(data = canada_map, aes(x = x, y = y), alpha = .1) +
  coord_quickmap()
map_plot + 
  geom_capellini(aes(tf = precipl10), width = 3, height = 5, colour = "blue") +
map_plot + 
   geom_capellini(aes(tf = temp), width = 3, height = 5, colour = "red")
```

# Wrangling `tf`s inside data frames

## Wrangling `tf`s inside data frames: `dplyr`

**`dplyr`** verbs **`filter`**, **`select`**, **`mutate`**, **`summarize`** work on **`tf`**-columns - e.g.:

```{r, dplyr}
# group-wise functional means:
dti %>% group_by(case, sex) %>% summarize(mean_rcst = mean(rcst, na.rm = TRUE))       %>% ungroup
# which subjects go below cca = .26:
dti %>% filter(tf_anywhere(cca, value < .26))
```

## Wrangling `tf`s inside data frames: `dplyr`

```{r, dplyr2}
# mutate and create derived functional data
dti %>%
  mutate(rcst_smooth = tfb(rcst, k = 15, verbose = FALSE),
    rcst_deriv = tf_derive(rcst_smooth)) %>%
  glimpse
```

## Wrangling `tf`s inside data frames: `tidyr`

`tidyfun` provides `tf_` variants of `tidyr`-verbs to reshape and reformat functional data while keeping it in sync with other covariates:

\vskip 2em

- `tf_spread:` `tf` $\rightarrow$ columns for each `arg`
- `tf_gather:` columns for each `arg` $\rightarrow$ `tf`

\vskip .5em

- `tf_nest  :` data in long format (`id`, `arg`, `value`)  $\rightarrow$ `tf`
- `tf_unnest:` `tf` $\rightarrow$ data in long format (`id`, `arg`, `value`)  

## Wrangling `tf`s inside data frames: `tidyr`

```{r, tidyr}
# *spread* tf out into columns for each arg
dti_wide = dti %>% tf_spread(cca); dti_wide[, 1:10] %>% glimpse()  

# *gather* columns representing f(<arg>) into a single tf-column 
dti_wide %>% tf_gather(matches("cca_")) %>% glimpse()
```

## Wrangling `tf`s inside data frames: `tidyr`


```{r, tidyr2}
# unnest tf by writing 3 loong columns id, arg, value:
# (will try to avoid unnecessary duplication of columns)
dti_long = dti %>% tf_unnest(cca); dti_long %>% glimpse()  

# create tf ("nested data") by re-combining (id, arg, value):
dti_long %>% tf_nest(cca_value, .id = cca_id, .arg = cca_arg) %>% glimpse()
```

# Wrap-Up & Discussion

##

What seems too difficult to you...?

What seems too sloppy/dangerous/simplistic to you..?

What additional features would you need...?


## What is missing:

- Wavelet basis representation: How?

## What is missing:

- Warping/Registration: Which methods?

## What is missing:

- Integration with / bridges to existing packages: `fda`, `fda.usc`, `refund`, `fdasrvf`, `registr`, ...

##  

\begin{center}
\textbf{... I like it. You might, too, give it a spin!}\footnote{\emph{Caveat emptor. Currently a moving target, still a beta-version.}}


\href{https://fabian-s.github.io/tidyfun/}{\texttt{https://fabian-s.github.io/tidyfun/}}

Get it: \texttt{devtools::install\_github("fabian-s/tidyfun")}

\end{center}

## Outlook

Next up:

  - integrate `fda` bases & penalties, wavelet bases
  - functions for registering & warping
  - validate & test
  
Version 1.0:

  - extensions for multivariable functions
  - much more extensive documentation & tests
  - integration with **`refund`** for modeling and inference

# Thanks. \vskip 2em \href{https://github.com/fabian-s/tidyfun}{\texttt{https://github.com/fabian-s/tidyfun}} \vskip 2em \tiny (I don't even have references.)
